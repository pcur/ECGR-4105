{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 582,
   "id": "a85dd9bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from matplotlib.colors import ListedColormap\n",
    "import torch\n",
    "from torch.nn.functional import normalize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 583,
   "id": "ea8f0f52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.10.2'"
      ]
     },
     "execution_count": 583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainSize = 0.8\n",
    "testSize = 0.2\n",
    "torch.version.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08ea30e8",
   "metadata": {},
   "source": [
    "\n",
    "Problem 1 (20 pts):\n",
    "\n",
    "In our temperature prediction example, letâ€™s change our model to a non-linear system. Consider the following description for our model:\n",
    "\n",
    "w2 * t_u ** 2 + w1 * t_u + b.\n",
    "\n",
    "1.a Modify the training loop properly to accommodate this redefinition. \n",
    "\n",
    "1.b Use 5000 epochs for your training. Explore different learning rates from 0.1 to 0.0001 (you need four separate trainings). Report your loss for every 500 epochs per training.\n",
    "\n",
    "1.c Pick the best non-linear model and compare your final best loss against the linear model that we did during the lecture. For this, visualize the non-linear model against the linear model over the input dataset, as we did during the lecture. Is the actual result better or worse than our baseline linear model?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 584,
   "id": "01ae0123",
   "metadata": {},
   "outputs": [],
   "source": [
    "#from slide 3, temperature data\n",
    "t_c = [0.5, 14.0, 15.0, 28.0, 11.0, 8.0, 3.0, -4.0, 6.0, 13.0, 21.0]\n",
    "t_u = [35.7, 55.9, 58.2, 81.9, 56.3, 48.9, 33.9, 21.8, 48.4, 60.4, 68.4]\n",
    "#t_c = normalize(torch.tensor(t_c), p=1.0, dim = 0)\n",
    "#t_u = normalize(torch.tensor(t_u), p=1.0, dim = 0)\n",
    "t_c = torch.tensor(t_c)\n",
    "t_u = torch.tensor(t_u)\n",
    "t_un = 0.05 * t_u\n",
    "\n",
    "\n",
    "w = torch.tensor([1.0,1.0])\n",
    "b = torch.tensor([0.0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 585,
   "id": "ddc4194e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model (t_u, w, b):\n",
    "    return w[0] * t_u ** 2 + w[1] * t_u + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 586,
   "id": "8794c220",
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(t_p, t_c):\n",
    "    squared_diffs = (t_p - t_c)**2\n",
    "    return squared_diffs.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 587,
   "id": "5ba8a8cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "delta = 0.1\n",
    "loss_delta_w = (loss_fn(model(t_un, w + delta, b), t_c) - loss_fn(model(t_un, w - delta, b), t_c)) / (2.0 * delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 588,
   "id": "7c7d98ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "w = w - learning_rate * loss_delta_w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 589,
   "id": "ce504611",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_delta_b = (loss_fn(model(t_u, w, b + delta), t_c) - loss_fn(model(t_u, w, b - delta), t_c)) / (2.0 * delta)\n",
    "b = b - learning_rate * loss_delta_b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 590,
   "id": "668a1578",
   "metadata": {},
   "outputs": [],
   "source": [
    "def dloss_fn(t_p, t_c):\n",
    "    dsq_diffs = 2 * (t_p - t_c) / t_p.size(0)\n",
    "    return dsq_diffs\n",
    "\n",
    "#d/dw w2*tu^2 + w1*tu + b = 2*w2*tu + tu\n",
    "def dmodel_dw(t_u, w, b):\n",
    "    return 2*w[0]*t_u + t_u\n",
    "\n",
    "#d/db w2*tu^2 + w1*tu + b = 1\n",
    "def dmodel_db(t_u, w, b):\n",
    "    return 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "79ab20bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grad_fn(t_u, t_c, t_p, w, b):\n",
    "    dloss_dtp = dloss_fn(t_p, t_c)\n",
    "    dloss_dw1 = dloss_dtp * dmodel_dw(t_u, w, b)\n",
    "    dloss_dw2 = dloss_dtp * dmodel_dw(t_u, w, b)\n",
    "    dloss_db = dloss_dtp * dmodel_db(t_u, w, b)\n",
    "    return torch.stack([dloss_dw1.sum(), dloss_dw2.sum(), dloss_db.sum()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 592,
   "id": "3edc1968",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(n_epochs, lr, params, t_u, t_c):\n",
    "    for epoch in range(1, n_epochs + 1):\n",
    "        w[1], w[0], b = params\n",
    "        \n",
    "        t_p = model(t_u, w, b)\n",
    "        loss = loss_fn(t_p, t_c)\n",
    "        grad = grad_fn(t_u, t_c, t_p, w, b)\n",
    "        \n",
    "        params = params - lr * grad\n",
    "        if (epoch % 500 == 0):\n",
    "            print ('Epoch %d, Loss %f' % (epoch, float(loss)))\n",
    "    \n",
    "    return params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 593,
   "id": "976bfd1c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss nan\n",
      "Epoch 1000, Loss nan\n",
      "Epoch 1500, Loss nan\n",
      "Epoch 2000, Loss nan\n",
      "Epoch 2500, Loss nan\n",
      "Epoch 3000, Loss nan\n",
      "Epoch 3500, Loss nan\n",
      "Epoch 4000, Loss nan\n",
      "Epoch 4500, Loss nan\n",
      "Epoch 5000, Loss nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([nan, nan, nan])"
      ]
     },
     "execution_count": 593,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(n_epochs = 5000, lr = 1e-1, params = torch.tensor([1.0,1.0,0.0]), t_u = t_un, t_c = t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 594,
   "id": "6aaaf5cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss 14.905792\n",
      "Epoch 1000, Loss 14.919845\n",
      "Epoch 1500, Loss 14.919877\n",
      "Epoch 2000, Loss 14.919877\n",
      "Epoch 2500, Loss 14.919877\n",
      "Epoch 3000, Loss 14.919877\n",
      "Epoch 3500, Loss 14.919877\n",
      "Epoch 4000, Loss 14.919877\n",
      "Epoch 4500, Loss 14.919877\n",
      "Epoch 5000, Loss 14.919877\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 0.8937,  0.8937, -1.8435])"
      ]
     },
     "execution_count": 594,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(n_epochs = 5000, lr = 1e-2, params = torch.tensor([1.0,1.0,0.0]), t_u = t_un, t_c = t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 595,
   "id": "b888560f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss 9.636432\n",
      "Epoch 1000, Loss 7.903916\n",
      "Epoch 1500, Loss 6.577419\n",
      "Epoch 2000, Loss 5.562541\n",
      "Epoch 2500, Loss 4.786726\n",
      "Epoch 3000, Loss 4.194201\n",
      "Epoch 3500, Loss 3.742140\n",
      "Epoch 4000, Loss 3.397652\n",
      "Epoch 4500, Loss 3.135494\n",
      "Epoch 5000, Loss 2.936308\n"
     ]
    }
   ],
   "source": [
    "params = training_loop(n_epochs = 5000, lr = 1e-3, params = torch.tensor([1.0,1.0,0.0]), t_u = t_un, t_c = t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 596,
   "id": "a9ace2f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 500, Loss 11.638963\n",
      "Epoch 1000, Loss 11.391587\n",
      "Epoch 1500, Loss 11.150748\n",
      "Epoch 2000, Loss 10.916253\n",
      "Epoch 2500, Loss 10.687913\n",
      "Epoch 3000, Loss 10.465536\n",
      "Epoch 3500, Loss 10.249030\n",
      "Epoch 4000, Loss 10.038197\n",
      "Epoch 4500, Loss 9.832887\n",
      "Epoch 5000, Loss 9.633007\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor([ 1.2221,  1.2221, -0.8447])"
      ]
     },
     "execution_count": 596,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_loop(n_epochs = 5000, lr = 1e-4, params = torch.tensor([1.0,1.0,0.0]), t_u = t_un, t_c = t_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 597,
   "id": "91d5eeb2",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2093373291.py, line 6)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  Cell \u001b[1;32mIn [597], line 6\u001b[1;36m\u001b[0m\n\u001b[1;33m    fig = plt.figure(dpi = 600)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mSyntaxError\u001b[0m\u001b[1;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "t_p = model(t_un, *params[0,1].tolist(), *params[2].item()\n",
    "\n",
    "fig = plt.figure(dpi = 600)\n",
    "plt.xlabel(\"Temperature (F)\")\n",
    "plt.ylabel(\"Temperature (C)\")\n",
    "plt.plot(t_u.numpy(), t_p.detach().numpy())\n",
    "plt.plot(t_u.numpy(), t_c.numpy(), 'o')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f373ba49",
   "metadata": {},
   "source": [
    "\n",
    "Problem 2 (30 pts):\n",
    "\n",
    "2.a. Develop preprocessing and a training loop to train a linear regression model that predicts housing price based on the following input variables:\n",
    "\n",
    "area, bedrooms, bathrooms, stories, parking\n",
    "\n",
    "For this, you need to use the housing dataset. For training and validation use 80% (training) and 20% (validation) split. Identify the best parameters for your linear regression model, based on the above input variables. In this case, you will have six parameters:\n",
    "\n",
    "U=W5*X5 + W4*X4 + W3*X3 + W2*X2 + W1*X1 + B\n",
    "\n",
    "2.b Use 5000 epochs for your training. Explore different learning rates from 0.1 to 0.0001 (you need four separate trainings). Report your loss and validation accuracy for every 500 epochs per each training. Pick the best linear model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 620,
   "id": "1f547b05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0, 3, 1, 4]), tensor([2]))"
      ]
     },
     "execution_count": 620,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "housing = pd.read_csv('https://raw.githubusercontent.com/pcur/ECGR-4105/main/Homework%201/Housing.csv')\n",
    "\n",
    "Y_house = housing.values[:,0]\n",
    "t_c = housing.values[:,0]\n",
    "\n",
    "area = torch.tensor(housing.values[:,1].reshape(len(Y_house),1).tolist())\n",
    "rooms = torch.tensor(housing.values[:,2].reshape(len(Y_house),1).tolist())\n",
    "bath = torch.tensor(housing.values[:,3].reshape(len(Y_house),1).tolist())\n",
    "floor = torch.tensor(housing.values[:,4].reshape(len(Y_house),1).tolist())\n",
    "park = torch.tensor(housing.values[:,10].reshape(len(Y_house),1).tolist())\n",
    "\n",
    "t_u = torch.stack((area,rooms,bath,floor,park))\n",
    "\n",
    "n_samples = t_u.shape[0]\n",
    "n_val = int(0.2 * n_samples)\n",
    "\n",
    "shuffled_indices = torch.randperm(n_samples)\n",
    "\n",
    "train_indices = shuffled_indices[:-n_val]\n",
    "val_indices = shuffled_indices[-n_val:]\n",
    "\n",
    "train_indices, val_indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 615,
   "id": "9ab83a7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_t_c = t_c[train_indices]\n",
    "train_t_u = t_u[train_indices]\n",
    "\n",
    "val_t_c = t_c[val_indices]\n",
    "val_t_u = t_u[val_indices]\n",
    "\n",
    "train_t_un = 0.1 * train_t_u\n",
    "val_t_un = 0.1 * val_t_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c53dec1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def model (t_u, w, b):\n",
    "    return w[0] * t_u ** 2 + w[1] * t_u + b "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 621,
   "id": "dd1c2851",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop (n_epochs, optimizer, params, train_t_u, val_t_u, train_t_c, val_t_c):\n",
    "    for epoch in range(1,n_epochs + 1):\n",
    "        train_t_p = model(train_t_u, *params)\n",
    "        train_loss = loss_fn(train_t_p, train_t_c)\n",
    "        \n",
    "        val_t_p = model(val_t_u, *params)\n",
    "        val_loss = loss_fn(val_t_p, val_t_c)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        train_loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if epoch % 500 == 0:\n",
    "            print(f\"Epoch {epoch}, Training loss {train_loss.item():.4f},\"\n",
    "                 f\" Validation loss {val_loss.item():.4f}\")\n",
    "    return params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb379bae",
   "metadata": {},
   "source": [
    "\n",
    "Problem 3 (50 pts):\n",
    "\n",
    "3.a Build a fully connected neural network for the housing dataset you did in previous problem. For training and validation use 80% (training) and 20% (validation) split. For this part, only use one hidden layer with 8 nodes. Train your network for 200 epochs. Report your training time, training loss, and evaluation accuracy after 200 epochs. Analyze your results in your report. Make sure to submit your code by providing the GitHub URL of your course repository for this course. (15pts)\n",
    "\n",
    "3.b Extend your network with two more additional hidden layers, like the example we did in lecture. Train your network for 200 epochs. Report your training time, training loss, and evaluation accuracy after 200 epochs. Analyze your results in your report. Make sure to submit your code by providing the GitHub URL of your course repository for this course. Analyze your results in your report and compare your model size and accuracy over the baseline implementation in Problem1. a. Do you see any over-fitting? Make sure to submit your code by providing the GitHub URL of your course repository for this course. (25pts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "927cdb66",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
